{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpf/.conda/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "\n",
    "def get_embds_score(t5, pred, gt):\n",
    "    pred_embds = t5.encode(pred, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1)\n",
    "    gt_embds = t5.encode(gt, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1)\n",
    "\n",
    "    res = abs((cosine_similarity(gt_embds, pred_embds)) ** 3)\n",
    "\n",
    "    return res[0][0]\n",
    "\n",
    "\n",
    "def filter_df(df):\n",
    "    df = df.fillna(\"\")\n",
    "\n",
    "    if \"subject\" in df.columns:\n",
    "        df = df[[\"original_text\", \"rewrite_prompt\", \"rewritten_text\", \"subject\"]].reset_index(drop=True)\n",
    "    \n",
    "    else:\n",
    "        df = df[[\"original_text\", \"rewrite_prompt\", \"rewritten_text\"]].reset_index(drop=True)\n",
    "    \n",
    "    df[\"original_text\"] = df[\"original_text\"].apply(lambda x: str(x).strip())\n",
    "    df[\"rewritten_text\"] = df[\"rewritten_text\"].apply(lambda x: str(x).strip())\n",
    "    df[\"rewrite_prompt\"] = df[\"rewrite_prompt\"].apply(lambda x: str(x).strip())\n",
    "\n",
    "    if \"subject\" in df.columns:\n",
    "        df[\"subject\"] = df[\"subject\"].apply(lambda x: str(x).strip())\n",
    "        df = df[df[\"subject\"].apply(lambda x: len(x) >= 5 and len(x) <= 200)].reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "    df = df[df[\"original_text\"].apply(lambda x: len(x) >= 300 and len(x) <= 2000)].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    df = df[df[\"rewritten_text\"].apply(lambda x: len(x) >= 200 and len(x) <= 3000)].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    df = df[df[\"rewrite_prompt\"].apply(lambda x: len(x) >= 5 and len(x) <= 500)].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset_pub(data_path=\"/kaggle/input/df_with_emb.parquet\"):\n",
    "    df = pd.read_parquet(data_path).fillna(\"\")\n",
    "    df = df[[\"original_text\", \"rewrite_prompt\", \"rewritten_text\"]].reset_index(drop=True)\n",
    "    df = filter_df(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_dataset_gpt():\n",
    "    data_list = [\n",
    "        # \"/kaggle/input/gemma_rewritten_text_exllama/proc_dataset_updated.csv\",\n",
    "        # \"/kaggle/input/pedro-data/data_subject.csv\",\n",
    "        # \"/kaggle/input/pedro-data/data_subject_2.csv\",\n",
    "        # \"/kaggle/input/pedro-data/data_subject_3.csv\",\n",
    "        \n",
    "        \"/home/mpf/code/kaggle/llm-prompt/selected_df_optim.csv\"\n",
    "    ]\n",
    "    df = pd.concat([pd.read_csv(data) for data in data_list], ignore_index=True)\n",
    "    df = filter_df(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_embds_path(t5, text_list, path):\n",
    "    path = Path(path)\n",
    "\n",
    "    # if path.exists():\n",
    "    if 0:\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    \n",
    "    \n",
    "    # text_list = [\"\".join([t for t in text if t.isalpha() or t in (\" \",)]) for text in text_list]\n",
    "    # print(text_list[:10])\n",
    "\n",
    "    embds = t5.encode(text_list, normalize_embeddings=True, show_progress_bar=True, batch_size=8)\n",
    "    np.save(path, embds, allow_pickle=True)\n",
    "\n",
    "    return embds\n",
    "\n",
    "\n",
    "def calc_score(t5, prompt, embds):\n",
    "    prompt_embds = t5.encode(prompt, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1)\n",
    "    res = ((cosine_similarity(embds, prompt_embds)) ** 3).mean()\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_dataset_pedro():\n",
    "    # prompts = json.load(open(\"/home/mpf/code/kaggle/pedro-llm-prompt/src/data_generation/prompts_selected.json\"))\n",
    "    prompts = json.load(open(\"/home/mpf/code/kaggle/pedro-llm-prompt/data/prompts_selected.json\"))\n",
    "    df = pd.DataFrame({\"rewrite_prompt\": prompts})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pub = get_dataset_pub()\n",
    "# df_gpt = get_dataset_gpt()\n",
    "df_gpt = get_dataset_pedro()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5085/5085 [00:51<00:00, 98.91it/s] \n",
      "Batches: 100%|██████████| 202/202 [00:02<00:00, 85.54it/s] \n"
     ]
    }
   ],
   "source": [
    "t5 = SentenceTransformer(\"sentence-transformers/sentence-t5-base\", device=device)\n",
    "\n",
    "embds_pub = get_embds_path(t5, df_pub[\"rewrite_prompt\"].tolist(), \"/kaggle/working/llm_prompt_embds_pub.npy\")\n",
    "embds_gpt = get_embds_path(t5, df_gpt[\"rewrite_prompt\"].tolist(), \"/kaggle/working/llm_prompt_embds_gpt.npy\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40676\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "print(len(embds_pub))\n",
    "print(len(embds_gpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5021735\n",
      "0.5205153\n",
      "0.56059414\n",
      "0.6021226\n",
      "0.56864166\n",
      "0.61298794\n",
      "0.53580457\n"
     ]
    }
   ],
   "source": [
    "embds = embds_pub\n",
    "# embds = embds_gpt\n",
    "\n",
    "print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.', embds))\n",
    "print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.</s>', embds))\n",
    "print(calc_score(t5, 'Improve the text to this.', embds))\n",
    "print(calc_score(t5, 'Improve the text to this.</s>', embds))\n",
    "print(calc_score(t5, 'Rewrite the text to this.', embds))\n",
    "print(calc_score(t5, 'Rewrite the text to this.</s>', embds))\n",
    "print(calc_score(t5, 'Modify text better.', embds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6432702\n",
      "0.64625883\n",
      "0.6402337\n",
      "0.64625883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# embds = embds_pub\n",
    "embds = embds_gpt\n",
    "\n",
    "# print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.', embds))\n",
    "# print(calc_score(t5, 'Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.</s>', embds))\n",
    "# print(calc_score(t5, 'Improve the text to this.', embds))\n",
    "# print(calc_score(t5, 'Improve the text to this.</s>', embds))\n",
    "# print(calc_score(t5, 'Rewrite the text to this.', embds))\n",
    "# print(calc_score(t5, 'Rewrite the text to this.</s>', embds))\n",
    "\n",
    "\n",
    "# print(calc_score(t5, 'Improve rephrase text manner this written to has character in style.', embds))\n",
    "# print(calc_score(t5, 'Improve rephrase text manner this written to has character in style.', embds))\n",
    "print(calc_score(t5, 'Improve rephrase text manner this written to has character in style to .', embds))\n",
    "print(calc_score(t5, 'Improve text rephrase manner this written being sounds describe or written to .', embds))\n",
    "\n",
    "\n",
    "print(calc_score(t5, 'Improve text rephrase manner this written being sounds describe or written .', embds))\n",
    "print(calc_score(t5, 'Improve rephrase text manner this piece tone into written object provided .', embds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Improve the text to this.</s>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59822756"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tids = t5.tokenizer(['Improve the text to this.</s>'], return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "\n",
    "print(t5.tokenizer.batch_decode(tids[\"input_ids\"]))\n",
    "\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    tembds = t5(tids)[\"sentence_embedding\"].cpu().numpy()\n",
    "\n",
    "cos_sim = (cosine_similarity(tembds, embds) ** 3).mean()\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('customer support', 284),\n",
       " ('persuasive using', 252),\n",
       " ('using exclusive', 252),\n",
       " ('simpler and', 218),\n",
       " ('see the', 189),\n",
       " ('past tense', 183),\n",
       " ('and upholds', 172),\n",
       " ('emotions evoked', 169),\n",
       " ('abbreviations to', 162),\n",
       " ('concepts such', 147)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_most_common_ngrams(texts, n=2, top_n=5):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    count_values = X.toarray().sum(axis=0)\n",
    "    vocabulary = vectorizer.vocabulary_\n",
    "    freq_dist = Counter(dict(zip(vocabulary.keys(), count_values)))\n",
    "    return freq_dist.most_common(top_n)\n",
    "\n",
    "n_grams = get_most_common_ngrams(df_gpt[\"rewrite_prompt\"].tolist(), n=2, top_n=10)\n",
    "\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989,\n",
       " ['the', 'a', 'and', 'this', 'of', 'text', 'rewrite', 'in', 'more', 'tone'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = {}\n",
    "\n",
    "embds = embds_gpt\n",
    "text_list = df_gpt[\"rewrite_prompt\"].tolist()\n",
    "\n",
    "\n",
    "# embds = embds_pub\n",
    "# text_list = df_pub[\"rewrite_prompt\"].tolist()\n",
    "\n",
    "\n",
    "for i, text in enumerate(text_list):    \n",
    "    words = text.split()\n",
    "    \n",
    "    for word in words:\n",
    "        word = \"\".join(filter(str.isalnum, word)).lower().strip()\n",
    "        \n",
    "        if not word:\n",
    "            continue\n",
    "\n",
    "        if word not in bow:\n",
    "            bow[word] = 0\n",
    "        \n",
    "        bow[word] += 1\n",
    "        \n",
    "bow_tup = [(k, v) for k, v in bow.items()]\n",
    "sorted_bow = sorted(bow_tup, key=lambda x: x[1], reverse=True)\n",
    "sorted_bow = list(sorted_bow)[:1000]\n",
    "\n",
    "all_words = [tup[0] for tup in sorted_bow]\n",
    "# all_words = [w for w in all_words if w not in (\"portrayal\", \"conveying\", \"convey\", \"compelling\", \"compel\", \"expressing\", \"improving\", \"retell\", \"reword\", \"engaging\", \"storytelling\")]\n",
    "all_words = [w for w in all_words if w not in (\"portrayal\", \"conveying\", \"convey\", \"compelling\", \"compel\", \"expressing\", \"improving\", \"retell\", \"reword\", \"engaging\", \"storytelling\", \"person\", \"to\")]\n",
    "\n",
    "# all_words = all_words + [word + \",\" for word in all_words]\n",
    "\n",
    "len(all_words), all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.53978646 rephrase\n",
      "1 0.5973522 rephrase text\n",
      "2 0.6075368 improve rephrase text\n",
      "3 0.6167569 modify text better exude\n",
      "4 0.62476146 improve text this sounds if\n",
      "5 0.6342309 improve text this sounds within manner\n",
      "6 0.6368616 improve rephrase text manner this piece tone\n",
      "7 0.6409052 improve rephrase text manner this piece tone into\n",
      "8 0.6420898 improve rephrase text manner this piece tone into given\n",
      "9 0.64481306 improve rephrase text manner this piece tone form product into\n",
      "10 0.64510465 improve rephrase text manner this piece tone into written object provided\n",
      "11 0.6475574 improve rephrase text manner this piece tone form product into written given\n",
      "12 0.64904976 improve rephrase text manner this piece tone form product into from current place\n",
      "13 0.6496401 improve rephrase text manner this piece tone into written object within convincing appealing same\n",
      "14 0.65114844 improve rephrase text manner this piece tone into written object within convincing suit current describing\n",
      "improve rephrase text manner this piece tone into written object within convincing suit current describing\n"
     ]
    }
   ],
   "source": [
    "beam_width = 50  # Number of beams to keep after each step\n",
    "num_words = 15  # Total number of words to generate\n",
    "all_beams = [([], 0)]  # Starting with empty sequence and 0 score\n",
    "\n",
    "for step in range(num_words):\n",
    "    new_beams = []\n",
    "    for sel_words, score in all_beams:\n",
    "        cur_text = \" \".join(sel_words)\n",
    "        if sel_words:\n",
    "            cur_text += \" \"\n",
    "        all_text = [cur_text + word for word in all_words]\n",
    "       \n",
    "        for i, t in enumerate(all_text):\n",
    "            t = t[0].upper() + t[1:]\n",
    "            if len(sel_words) >= 3:\n",
    "                t = t + \".\"\n",
    "                # t = t + \" to .\"\n",
    "            all_text[i] = t\n",
    "    \n",
    "        text_embds = t5.encode(all_text, normalize_embeddings=True, show_progress_bar=False, batch_size=8)\n",
    "        scores = (cosine_similarity(embds, text_embds) ** 3).mean(axis=0)\n",
    "        for i, new_score in enumerate(scores):\n",
    "            new_beams.append((sel_words + [all_words[i]], new_score))\n",
    "\n",
    "    # Keep only the best `beam_width` beams\n",
    "    all_beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "    \n",
    "    best = all_beams[0]\n",
    "    print(step, best[1], \" \".join(best[0]))\n",
    "\n",
    "# Select the best beam\n",
    "best_words, best_score = max(all_beams, key=lambda x: x[1])\n",
    "print(\" \".join(best_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 0.5397863 rephrase\n",
    "# 1 0.5973522 rephrase text\n",
    "# 2 0.6075368 improve rephrase text\n",
    "# 3 0.6167569 modify text better exude\n",
    "# 4 0.62476146 improve text this sounds if\n",
    "# 5 0.6342308 improve text this sounds within manner\n",
    "# 6 0.6368615 improve rephrase text manner this piece tone\n",
    "# 7 0.6409051 improve rephrase text manner this piece tone into\n",
    "# 8 0.6431984 improve rephrase text manner this written to has character\n",
    "# 9 0.64508 improve rephrase text manner this written to has character with\n",
    "# 10 0.6485689 improve rephrase text manner this written to has character in style\n",
    "# 11 0.650034 improve rephrase text manner this written to has character is in style\n",
    "# 12 0.65163815 improve rephrase text manner this written to has character has hear within fashion\n",
    "# 13 0.65164465 improve rephrase text manner this written to has character has hear there in style\n",
    "# 14 0.65171796 improve rephrase text manner this written to has character has hear there in style within\n",
    "# improve rephrase text manner this written to has character has hear there in style within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 0.5397863 rephrase\n",
    "# 1 0.5973522 rephrase text\n",
    "# 2 0.6075368 improve rephrase text\n",
    "# 3 0.6157136 improve text this describe\n",
    "# 4 0.62748814 improve text this sounds put\n",
    "# 5 0.6391686 improve text rephrase manner this written\n",
    "# 6 0.6386987 improve text rephrase manner this sounds written\n",
    "# 7 0.6417676 improve text rephrase manner this write sounds written\n",
    "# 8 0.64228374 improve text rephrase manner this written sounds describe written\n",
    "# 9 0.64566153 improve text rephrase manner this written sounds describe or written\n",
    "# 10 0.64625907 improve text rephrase manner this written being sounds describe or written\n",
    "# 11 0.64795214 improve text rephrase manner this body written sounds express or are describing\n",
    "# 12 0.6480724 improve text rephrase manner this body written sounds express or are describing written\n",
    "# 13 0.65008354 improve text rephrase manner this body written sounds express or are describing an written\n",
    "# 14 0.6513185 improve text rephrase manner this body written sounds express or are describing a was written\n",
    "# improve text rephrase manner this body written sounds express or are describing a was written"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
